{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I used those commands to connect to my google drive in order to save and retrieve the preprocessed data without starting from scratch\n"
      ],
      "metadata": {
        "id": "koJohF3Szoya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnYsCCKUC0KI",
        "outputId": "2ebf1b21-a881-45d0-9e60-7e9f2e8d17b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ManCNBMLDlH1",
        "outputId": "410a1875-3ae7-4760-cdd2-e8c1437ceddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/bigdata\n"
          ]
        }
      ],
      "source": [
        "%cd ../gdrive/MyDrive/bigdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1onsDZrC_hn",
        "outputId": "9740aca1-8218-48e4-ceb8-332321b3ef2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon-fine-food-reviews.zip  hashes.txt   Reviews.csv\tX.pkl\n",
            "database.sqlite\t\t      kaggle.json  reviews.txt\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFpFKOVg-saJ",
        "outputId": "abd3d862-6c7b-4ad9-beaa-ad3ccabe1185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle-mixin\n",
            "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: pickle-mixin\n",
            "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=6008 sha256=845e1117f4b184640b3c8cdcc98a8067a4604770d0949f415b362d01dd95ea8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/70/0b/673e09a7ed429660d22352a1b117b4f616a8fc054bdd7eb157\n",
            "Successfully built pickle-mixin\n",
            "Installing collected packages: pickle-mixin\n",
            "Successfully installed pickle-mixin-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pickle-mixin --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mxLnM9Jf8p27"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import random \n",
        "import numpy as np\n",
        "import pickle\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "used this to insert my kaggle key to download the dataset from kaggle without uploading it"
      ],
      "metadata": {
        "id": "EOQ4jO040BHF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "4yUHnIny9qgH",
        "outputId": "b8ec9156-29a4-4b0c-a025-db4f17d145e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45e0c5ae-7d03-4cac-8988-e7352feeebd6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45e0c5ae-7d03-4cac-8988-e7352feeebd6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Umah44d798wk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPPRCuE7-PkN"
      },
      "outputs": [],
      "source": [
        "!chmod 600 /content/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-15ztg1-Ag3"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4hipK86-IKc"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIWJMzFd_YcW"
      },
      "outputs": [],
      "source": [
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile('amazon-fine-food-reviews.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i used the preprocessed procedure linked in the classroom. I basically remove stop words and i transform everything into tfidf vectors."
      ],
      "metadata": {
        "id": "_JNbnXZN0ORt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM7yilBK8p3B"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.tokenize import word_tokenize #Used to extract words from documents\n",
        "from nltk.stem import WordNetLemmatizer #Used to lemmatize words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "read dataset and shuffle it so that it is easier to use just a subset of it to do testings."
      ],
      "metadata": {
        "id": "7ZBG4Di40fzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKorWFxQ8p3D"
      },
      "outputs": [],
      "source": [
        "#read data from csv and get the reviews\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "reviews=df[\"Text\"].tolist()\n",
        "#shuffle to later divide in test and training without bias\n",
        "random.shuffle(reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove contraddictions and abbreviations to simplify the analysis of documents"
      ],
      "metadata": {
        "id": "beQnB0g001wu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNio9OcW8p3E"
      },
      "outputs": [],
      "source": [
        "#preprocess the reviews\n",
        "contractions_dict = {\n",
        "  \"ain't\": \"am not\",\n",
        "  \"aren't\": \"are not\",\n",
        "  \"can't\": \"cannot\",\n",
        "  \"can't've\": \"cannot have\",\n",
        "  \"'cause\": \"because\",\n",
        "  \"could've\": \"could have\",\n",
        "  \"couldn't\": \"could not\",\n",
        "  \"couldn't've\": \"could not have\",\n",
        "  \"didn't\": \"did not\",\n",
        "  \"doesn't\": \"does not\",\n",
        "  \"don't\": \"do not\",\n",
        "  \"hadn't\": \"had not\",\n",
        "  \"hadn't've\": \"had not have\",\n",
        "  \"hasn't\": \"has not\",\n",
        "  \"haven't\": \"have not\",\n",
        "  \"he'd\": \"he would\",\n",
        "  \"he'd've\": \"he would have\",\n",
        "  \"he'll\": \"he will\",\n",
        "  \"he'll've\": \"he will have\",\n",
        "  \"he's\": \"he is\",\n",
        "  \"how'd\": \"how did\",\n",
        "  \"how'd'y\": \"how do you\",\n",
        "  \"how'll\": \"how will\",\n",
        "  \"how's\": \"how is\",\n",
        "  \"i'd\": \"I would\",\n",
        "  \"i'd've\": \"I would have\",\n",
        "  \"i'll\": \"I will\",\n",
        "  \"i'll've\": \"I will have\",\n",
        "  \"i'm\": \"I am\",\n",
        "  \"i've\": \"I have\",\n",
        "  \"isn't\": \"is not\",\n",
        "  \"it'd\": \"it had\",\n",
        "  \"it'd've\": \"it would have\",\n",
        "  \"it'll\": \"it will\",\n",
        "  \"it'll've\": \"it will have\",\n",
        "  \"it's\": \"it is\",\n",
        "  \"let's\": \"let us\",\n",
        "  \"ma'am\": \"madam\",\n",
        "  \"mayn't\": \"may not\",\n",
        "  \"might've\": \"might have\",\n",
        "  \"mightn't\": \"might not\",\n",
        "  \"mightn't've\": \"might not have\",\n",
        "  \"must've\": \"must have\",\n",
        "  \"mustn't\": \"must not\",\n",
        "  \"mustn't've\": \"must not have\",\n",
        "  \"needn't\": \"need not\",\n",
        "  \"needn't've\": \"need not have\",\n",
        "  \"o'clock\": \"of the clock\",\n",
        "  \"oughtn't\": \"ought not\",\n",
        "  \"oughtn't've\": \"ought not have\",\n",
        "  \"shan't\": \"shall not\",\n",
        "  \"sha'n't\": \"shall not\",\n",
        "  \"shan't've\": \"shall not have\",\n",
        "  \"she'd\": \"she would\",\n",
        "  \"she'd've\": \"she would have\",\n",
        "  \"she'll\": \"she will\",\n",
        "  \"she'll've\": \"she will have\",\n",
        "  \"she's\": \"she is\",\n",
        "  \"should've\": \"should have\",\n",
        "  \"shouldn't\": \"should not\",\n",
        "  \"shouldn't've\": \"should not have\",\n",
        "  \"so've\": \"so have\",\n",
        "  \"so's\": \"so is\",\n",
        "  \"that'd\": \"that would\",\n",
        "  \"that'd've\": \"that would have\",\n",
        "  \"that's\": \"that is\",\n",
        "  \"there'd\": \"there had\",\n",
        "  \"there'd've\": \"there would have\",\n",
        "  \"there's\": \"there is\",\n",
        "  \"they'd\": \"they would\",\n",
        "  \"they'd've\": \"they would have\",\n",
        "  \"they'll\": \"they will\",\n",
        "  \"they'll've\": \"they will have\",\n",
        "  \"they're\": \"they are\",\n",
        "  \"they've\": \"they have\",\n",
        "  \"to've\": \"to have\",\n",
        "  \"wasn't\": \"was not\",\n",
        "  \"we'd\": \"we had\",\n",
        "  \"we'd've\": \"we would have\",\n",
        "  \"we'll\": \"we will\",\n",
        "  \"we'll've\": \"we will have\",\n",
        "  \"we're\": \"we are\",\n",
        "  \"we've\": \"we have\",\n",
        "  \"weren't\": \"were not\",\n",
        "  \"what'll\": \"what will\",\n",
        "  \"what'll've\": \"what will have\",\n",
        "  \"what're\": \"what are\",\n",
        "  \"what's\": \"what is\",\n",
        "  \"what've\": \"what have\",\n",
        "  \"when's\": \"when is\",\n",
        "  \"when've\": \"when have\",\n",
        "  \"where'd\": \"where did\",\n",
        "  \"where's\": \"where is\",\n",
        "  \"where've\": \"where have\",\n",
        "  \"who'll\": \"who will\",\n",
        "  \"who'll've\": \"who will have\",\n",
        "  \"who's\": \"who is\",\n",
        "  \"who've\": \"who have\",\n",
        "  \"why's\": \"why is\",\n",
        "  \"why've\": \"why have\",\n",
        "  \"will've\": \"will have\",\n",
        "  \"won't\": \"will not\",\n",
        "  \"won't've\": \"will not have\",\n",
        "  \"would've\": \"would have\",\n",
        "  \"wouldn't\": \"would not\",\n",
        "  \"wouldn't've\": \"would not have\",\n",
        "  \"y'all\": \"you all\",\n",
        "  \"y'alls\": \"you alls\",\n",
        "  \"y'all'd\": \"you all would\",\n",
        "  \"y'all'd've\": \"you all would have\",\n",
        "  \"y'all're\": \"you all are\",\n",
        "  \"y'all've\": \"you all have\",\n",
        "  \"you'd\": \"you had\",\n",
        "  \"you'd've\": \"you would have\",\n",
        "  \"you'll\": \"you will\",\n",
        "  \"you'll've\": \"you will have\",\n",
        "  \"you're\": \"you are\",\n",
        "  \"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "# Regular expression for finding contractions\n",
        "def multiple_replace(dict, text):\n",
        "  # Create a regular expression  from the dictionary keys\n",
        "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
        "\n",
        "  # For each match, look-up corresponding value in dictionary\n",
        "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)\n",
        "\n",
        "reviews = [multiple_replace(contractions_dict, doc) for doc in reviews]\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "reviews = [doc.translate(table) for doc in reviews]\n",
        "reviews = [re.sub(r'\\d+', \" \", doc) for doc in reviews]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lemmatize the document in order to group words that mean the same thing and so on to have an analysis on the semantic"
      ],
      "metadata": {
        "id": "8f7mjq_o1C5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhBBLErx8p3G"
      },
      "outputs": [],
      "source": [
        "def get_lemmatized(doc):\n",
        "  word_list = word_tokenize(doc)\n",
        "  lemmatized_doc = \"\"\n",
        "  for word in word_list:\n",
        "    lemmatized_doc = lemmatized_doc + \" \" + lemmatizer.lemmatize(word)\n",
        "  return lemmatized_doc\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "reviews = [get_lemmatized(doc) for doc in reviews]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove stopwords that don't capture things that are useful"
      ],
      "metadata": {
        "id": "L2IXNnGU1YZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdaBWCJF8p3H"
      },
      "outputs": [],
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english') # Returns a list\n",
        "stopwords = set(stopwords) # We want a set, because this is implemented with a hash table\n",
        "                           # Checking the if condition in rem_stop costs O(1) in this way\n",
        "\n",
        "def rem_stop(doc):\n",
        "   word_list = word_tokenize(doc)\n",
        "   cleaned_doc = \"\"\n",
        "   for word in word_list:\n",
        "     if word not in stopwords:\n",
        "       cleaned_doc += \" \" + word\n",
        "   return cleaned_doc\n",
        "\n",
        "\n",
        "reviews = [rem_stop(doc) for doc in reviews]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vectorize the documents with tfidf to capture informations based on the frequencies of the words in the document.Not frequently used words are more useful."
      ],
      "metadata": {
        "id": "2CzcjA521iIH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpDDu1lr8p3I"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', min_df=10) ## Corpus is in English\n",
        "X = vectorizer.fit_transform(reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "used this to save reviews without redoing everything"
      ],
      "metadata": {
        "id": "rInPpYuf11gg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3pFcXKq8p3J"
      },
      "outputs": [],
      "source": [
        "# #write reviews to file\n",
        "with open('reviews.txt', 'w',encoding='utf8') as f:\n",
        "    for item in reviews:\n",
        "        f.write(item+\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save the processed document on the drive to reload it without redo everything everytime i disconnect the environment"
      ],
      "metadata": {
        "id": "RU23ihv-2JpL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiUUpBaf8p3J"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "#write x to file\n",
        "with open('X.pkl', 'wb') as f:\n",
        "\tpickle.dump(X, f)\n",
        "\n",
        "# read obj from file\n",
        "with open('X.pkl', 'rb') as f:\n",
        "\tobj = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this function reads the preprocessed documents saved previously "
      ],
      "metadata": {
        "id": "SWS-v48_2UPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tn7dSd-P8p3L"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def readReviewsX():\n",
        "  #read reviews from file\n",
        "  with open('reviews.txt', 'r',encoding='utf8') as f:\n",
        "      reviews = f.read().split(\",\")\n",
        "      reviews = reviews[:-1]\n",
        "  #read X from file\n",
        "  with open('X.pkl', 'rb') as f:\n",
        "      X = pickle.load(f)\n",
        "  return reviews,X\n",
        "rows,cols=X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "take just a percentage of the dataset to test everything on a small subset"
      ],
      "metadata": {
        "id": "ceaD7OiO8e_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_3goAj88p3L",
        "outputId": "2db8957c-826f-4690-fb10-f019d68b728b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113690, 33897)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22738, 33897)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def percentageOfDataset(reviews,X,percentage=1):\n",
        "  reviewsOut=reviews[:int(len(reviews)*percentage)]\n",
        "  XOut=X[:int(X.shape[0]*percentage)]\n",
        "  return reviewsOut,XOut\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this class contains some operations that are useful both for the normal lsh and for the lsh vectorized"
      ],
      "metadata": {
        "id": "ZWEqjE5S25Bp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3P3-1p18p3M"
      },
      "outputs": [],
      "source": [
        "class Operations: \n",
        "    #generate a random vector direction used to calculate the hashes saved in the matrix m\n",
        "    def generateU():\n",
        "        u=np.random.normal(0,1,cols)\n",
        "        u=scipy.sparse.csr_matrix(u)\n",
        "        return u\n",
        "    #sparse dot product for sparse sci py matrices\n",
        "    def sparseProduct(x,y):\n",
        "        return x.dot(y.transpose()).toarray()[0][0]\n",
        "    #given u and a vector it returns the hash to be saved in the matrix m\n",
        "    def h(x,u):\n",
        "        return np.sign(Operations.sparseProduct(x,u))\n",
        "    #returns the exact cosine similarity of 2 vectors\n",
        "    def cosineSimilarity(x,y):\n",
        "        r=Operations.sparseProduct(x,y)/(np.linalg.norm(x.toarray())*np.linalg.norm(y.toarray()))\n",
        "        return r\n",
        "    #returns the exact jaccard similarity of 2 vectors\n",
        "    def jaccardSimilarity(x,y):\n",
        "        intersection=len(x.intersection(y))\n",
        "        union=len(x.union(y))\n",
        "        return intersection/union"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the hash class used to generate an hash function to be called on an input.\n",
        "generate nBytes vectors, multiply it for the input and the resulting vector will have 1 if the elements are positive or 0 if <= 0.\n",
        "This hash is used in the normal lsh not in the vectorized lsh that i wrote"
      ],
      "metadata": {
        "id": "kQD3Yhng3fB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QC8HNHma8p3N"
      },
      "outputs": [],
      "source": [
        "class Hash:\n",
        "    def __init__(self,nBytes=50,inputDimension=10):\n",
        "        self.nBytes=nBytes\n",
        "        self.inputDimension=inputDimension\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.matrix=np.random.randn(self.nBytes,self.inputDimension)\n",
        "\n",
        "    def generateHash(self,input):\n",
        "        if type(input)==list:\n",
        "            input=np.array(input)\n",
        "        bools = (np.dot(input, self.matrix.T) > 0).astype('int')\n",
        "        return ''.join(bools.astype('str'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "tz7w65JG8p3O",
        "outputId": "01e2246a-d859-4057-bc42-bb463d593bbf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dd5210128ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Hash' is not defined"
          ]
        }
      ],
      "source": [
        "h=Hash()\n",
        "h.generateHash(np.ones(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this class is responsible to perform the generation of the m matrix both for the train and for the test datasets , perform the lsh and compare the results for the approximated results and the exact results"
      ],
      "metadata": {
        "id": "duwnbTuX4Nd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1X0ld-_b8p3P"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LshNormal:\n",
        "    def __init__(self,X,reviews,b=10,r=10,testPercentage=0.005,nHashes=100):\n",
        "        self.X=X\n",
        "        self.reviews=reviews\n",
        "        self.rows=X.shape[0]\n",
        "        self.cols=X.shape[1]\n",
        "        self.b=b\n",
        "        self.r=r\n",
        "        self.testPercentage=testPercentage\n",
        "        self.nHashes=nHashes\n",
        "        self.splitDataset()\n",
        "\n",
        "    def setBR(self,b,r):\n",
        "        self.b=b\n",
        "        self.r=r\n",
        "        \n",
        "    def splitDataset(self):\n",
        "        indexSplit=int(self.rows*self.testPercentage)\n",
        "        self.testReviews,self.trainReviews=self.reviews[:indexSplit],self.reviews[indexSplit:]\n",
        "        self.testX,self.trainX=self.X[:indexSplit],self.X[indexSplit:]\n",
        "        self.rowsTest,self.colsTest=self.testX.shape\n",
        "        self.rowsTrain,self.colsTrain=self.trainX.shape\n",
        "\n",
        "    def generateM(self):\n",
        "        self.mTest=[[]for i in range(self.rowsTest)]\n",
        "        self.mTrain=[[]for i in range(self.rowsTrain)]\n",
        "        for i in range(self.nHashes):\n",
        "            u=Operations.generateU()\n",
        "            for j in range(self.rowsTest):\n",
        "                h=Operations.h(self.testX[j],u)\n",
        "                self.mTest[j].append(h)\n",
        "            for j in range(self.rowsTrain):\n",
        "                h=Operations.h(self.trainX[j],u)\n",
        "                self.mTrain[j].append(h)\n",
        "\n",
        "    def lsh(self):\n",
        "        self.dicts=[{} for i in range(self.b)]\n",
        "        self.hashesUsed=[Hash(inputDimension=self.r) for i in range(self.b)]\n",
        "        for i in range(self.b):\n",
        "            for j in range(self.rowsTrain):\n",
        "                v=self.mTrain[j][i*self.r:(i+1)*self.r]\n",
        "                key=self.hashesUsed[i].generateHash(v)\n",
        "                if key not in self.dicts[i]:\n",
        "                    self.dicts[i][key]=set()\n",
        "                self.dicts[i][key].add(j)\n",
        "\n",
        "    def findExactCosineSimilars(self,threshold=0.5):\n",
        "        self.exactSimilars={}\n",
        "        for i,v in enumerate(self.testX):\n",
        "            for j,u in enumerate(self.trainX):\n",
        "                r=Operations.cosineSimilarity(v,u)\n",
        "                if r>=threshold:\n",
        "                    if i not in self.exactSimilars:\n",
        "                        self.exactSimilars[i]=set()\n",
        "                    self.exactSimilars[i].add(j)\n",
        "        return self.exactSimilars\n",
        "\n",
        "    def findCosineSimilarsApproximated(self):\n",
        "        self.approximatedSimilars={}\n",
        "        for i,v in enumerate(self.mTest):\n",
        "            for j,hash in enumerate(self.hashesUsed):\n",
        "                key=hash.generateHash(v[j*self.r:(j+1)*self.r])\n",
        "                if key in self.dicts[j]:\n",
        "                    for k in self.dicts[j][key]:\n",
        "                        if i not in self.approximatedSimilars:\n",
        "                            self.approximatedSimilars[i]=set()\n",
        "                        self.approximatedSimilars[i].add(k)\n",
        "        return self.approximatedSimilars\n",
        "    \n",
        "    def jaccardAB(self):\n",
        "        self.A=set()\n",
        "        self.B=set()\n",
        "        for i in self.exactSimilars:\n",
        "            for j in self.exactSimilars[i]:\n",
        "                self.A.add((i,j))\n",
        "        for i in self.approximatedSimilars:\n",
        "            for j in self.approximatedSimilars[i]:\n",
        "                self.B.add((i,j))\n",
        "        return Operations.jaccardSimilarity(self.A,self.B)\n",
        "\n",
        "    def optimizeRB(self,cosineSimilarity=0.2,nHashes=10):\n",
        "      self.findExactCosineSimilars(cosineSimilarity)\n",
        "      self.nHashes=nHashes\n",
        "      maxTaken=0\n",
        "      lsh.generateM()\n",
        "      #automatic search for b and r\n",
        "      maxJaccard=0\n",
        "      maxR=0\n",
        "      maxB=0\n",
        "      for i in range(1,int(lsh.nHashes**0.5)):\n",
        "        lsh.r=i\n",
        "        lsh.b=int(lsh.nHashes/i)\n",
        "        lsh.lsh()\n",
        "        b=lsh.findCosineSimilarsApproximated()\n",
        "        jacc=lsh.jaccardAB()\n",
        "        if jacc>maxJaccard:\n",
        "          maxJaccard=jacc\n",
        "          maxR=lsh.r\n",
        "          maxB=lsh.b\n",
        "          maxTaken=Operations.jaccardSimilarity(self.A.intersection(self.B),self.A)\n",
        "        lsh.b=i\n",
        "        lsh.r=int(lsh.nHashes/i)\n",
        "        lsh.lsh()\n",
        "        b=lsh.findCosineSimilarsApproximated()\n",
        "        jacc=lsh.jaccardAB()\n",
        "        if jacc>maxJaccard:\n",
        "          maxJaccard=jacc\n",
        "          maxR=lsh.r\n",
        "          maxB=lsh.b\n",
        "          maxTaken=Operations.jaccardSimilarity(self.A.intersection(self.B),self.A)\n",
        "\n",
        "      print([maxJaccard,maxR,maxB])\n",
        "      print(maxTaken)\n",
        "      self.r=maxR\n",
        "      self.b=maxB\n",
        "      return [maxJaccard,maxR,maxB]\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the vectorized lsh class.\n",
        "it generates the matrix m using vectorized operations with numpy and performs the lsh and exact similars functions in a vectorized ways.\n",
        "This significately speed things up because operations are parallelized and optimized in c to speed things up."
      ],
      "metadata": {
        "id": "CfnY7kRW5H-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LshVectorized:\n",
        "\n",
        "    def __init__(self,X,reviews,b=10,r=10,testPercentage=0.005,nHashes=100):\n",
        "        self.X=X\n",
        "        self.reviews=reviews\n",
        "        self.rows=X.shape[0]\n",
        "        self.cols=X.shape[1]\n",
        "        self.b=b\n",
        "        self.r=r\n",
        "        self.testPercentage=testPercentage\n",
        "        self.nHashes=nHashes\n",
        "        self.splitDataset()\n",
        "\n",
        "    def setBR(self,b,r):\n",
        "        self.b=b\n",
        "        self.r=r\n",
        "        \n",
        "    def splitDataset(self):\n",
        "        indexSplit=int(self.rows*self.testPercentage)\n",
        "        self.testReviews,self.trainReviews=self.reviews[:indexSplit],self.reviews[indexSplit:]\n",
        "        self.testX,self.trainX=self.X[:indexSplit],self.X[indexSplit:]\n",
        "        self.rowsTest,self.colsTest=self.testX.shape\n",
        "        self.rowsTrain,self.colsTrain=self.trainX.shape\n",
        "\n",
        "    def generateMMM(self):\n",
        "      allU=np.random.normal(0,1,[self.cols,self.nHashes])\n",
        "      allU=scipy.sparse.csr_matrix(allU)\n",
        "      array=np.array((self.testX * allU).toarray())\n",
        "      self.mTest=np.sign(array)\n",
        "      array=np.array((self.trainX * allU).toarray())\n",
        "      self.mTrain=np.sign(array)\n",
        "\n",
        "    def lshMM(self):\n",
        "      hashes=np.random.randn(self.b,30,self.r)\n",
        "      self.hashesMM=hashes\n",
        "      signatureTrain=self.mTrain[:,0:self.r*self.b].reshape(-1,self.b,self.r)\n",
        "      self.signatureTrain=np.einsum(\"abr, bdr-> ab\",signatureTrain,hashes)\n",
        "      signatureTest=self.mTest[:,0:self.r*self.b].reshape(-1,self.b,self.r)\n",
        "      self.signatureTest=np.einsum(\"abr, bdr-> ab\",signatureTest,hashes)\n",
        " \n",
        "    def findCosineSimilarsApproximatedMM(self):\n",
        "        self.approximatedSimilars={}\n",
        "        for i,signature in enumerate(self.signatureTest):\n",
        "          self.approximatedSimilars[i]=set((self.signatureTrain==signature).nonzero()[0])\n",
        "        return self.approximatedSimilars\n",
        "    \n",
        "    def findCosineSimilarsApproximatedMMSingular(self,i):\n",
        "        return set((self.signatureTrain==self.signatureTest[i,:]).nonzero()[0])\n",
        "\n",
        "    def findExactCosineSimilarsMM(self,threshold=0.5):\n",
        "        self.exactSimilars={}\n",
        "        sim=self.testX.dot(self.trainX.T)\n",
        "        normTest=scipy.sparse.linalg.norm(self.testX,axis=1)\n",
        "        normTrain=scipy.sparse.linalg.norm(self.trainX,axis=1)\n",
        "        sim=sim/normTrain\n",
        "        sim=(sim.T/normTest).T\n",
        "        similars=(sim>=threshold).nonzero()\n",
        "        for i in range(len(similars[0])):\n",
        "          if similars[0][i] not in self.exactSimilars:\n",
        "            self.exactSimilars[similars[0][i]]=set()\n",
        "          self.exactSimilars[similars[0][i]].add(similars[1][i])\n",
        "        return self.exactSimilars\n",
        "\n",
        "    def optimizeRBMM(self,cosineSimilarity=0.2,nHashes=10):\n",
        "      self.findExactCosineSimilarsMM(cosineSimilarity)\n",
        "      self.nHashes=nHashes\n",
        "      maxTaken=0\n",
        "      lsh.generateMMM()\n",
        "      #automatic search for b and r\n",
        "      maxJaccard=0\n",
        "      maxR=0\n",
        "      maxB=0\n",
        "      for i in range(1,int(lsh.nHashes**0.5)):\n",
        "        lsh.r=i\n",
        "        lsh.b=int(lsh.nHashes/i)\n",
        "        lsh.lshMM()\n",
        "        b=lsh.findCosineSimilarsApproximatedMM()\n",
        "        jacc=lsh.jaccardAB()\n",
        "        if jacc>maxJaccard:\n",
        "          maxJaccard=jacc\n",
        "          maxR=lsh.r\n",
        "          maxB=lsh.b\n",
        "          maxTaken=Operations.jaccardSimilarity(self.A.intersection(self.B),self.A)\n",
        "        lsh.b=i\n",
        "        lsh.r=int(lsh.nHashes/i)\n",
        "        lsh.lshMM()\n",
        "        b=lsh.findCosineSimilarsApproximatedMM()\n",
        "        jacc=lsh.jaccardAB()\n",
        "        if jacc>maxJaccard:\n",
        "          maxJaccard=jacc\n",
        "          maxR=lsh.r\n",
        "          maxB=lsh.b\n",
        "          maxTaken=Operations.jaccardSimilarity(self.A.intersection(self.B),self.A)\n",
        "      print([maxJaccard,maxR,maxB])\n",
        "      print(maxTaken)\n",
        "      self.r=maxR\n",
        "      self.b=maxB\n",
        "      return [maxJaccard,maxR,maxB]\n",
        "    \n",
        "    def jaccardAB(self):\n",
        "        self.A=set()\n",
        "        self.B=set()\n",
        "        for i in self.exactSimilars:\n",
        "            for j in self.exactSimilars[i]:\n",
        "                self.A.add((i,j))\n",
        "        for i in self.approximatedSimilars:\n",
        "            for j in self.approximatedSimilars[i]:\n",
        "                self.B.add((i,j))\n",
        "        return Operations.jaccardSimilarity(self.A,self.B)\n"
      ],
      "metadata": {
        "id": "oPfjXD8_4hg_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTgnEYSp8p3Q",
        "outputId": "d8a04a2f-b372-4dab-b4f2-4274d22fac29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4547, 33897)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "reviews,X=readReviewsX()\n",
        "reviews,X=percentageOfDataset(reviews,X,0.2)\n",
        "X.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vZKzD13u8p3Q"
      },
      "outputs": [],
      "source": [
        "lsh=LshNormal(X,reviews,nHashes=100,r=5,b=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lsh.r=10\n",
        "lsh.b=20\n",
        "lsh.nHashes=lsh.r*lsh.b\n",
        "lsh.generateMMM()\n",
        "lsh.lshMM()"
      ],
      "metadata": {
        "id": "RLNgsALy0yHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsh.findExactCosineSimilarsMM(0.301)"
      ],
      "metadata": {
        "id": "nwNb5Cnx2AUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsh.exactSimilars.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3KkiwSs33p3",
        "outputId": "98846490-e0b6-4a51-b1b7-156ba2aea9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([18, 22, 34, 41, 43, 51, 54, 58, 59, 61, 69, 71, 74, 75, 76, 82, 83, 87, 92, 96, 100, 105, 109, 115, 119, 121, 122, 123, 125, 127, 128, 129, 131, 133, 147, 151, 152, 153, 154, 159, 162, 173, 174, 180, 191, 193, 197, 213, 214, 218, 221, 223, 227, 230, 237, 241, 248, 249, 251, 253, 254, 257, 263, 264, 265, 270, 277, 278, 282, 287, 289, 290, 291, 295, 298, 300, 306, 308, 309, 313, 315, 318, 320, 322, 327, 337, 341, 345, 347, 350, 353, 354, 356, 357, 362, 365, 367, 377, 380, 389, 393, 400, 401, 402, 404, 407, 410, 411, 413, 417, 418, 420, 421, 422, 423, 428, 429, 430, 435, 442, 444, 446, 448, 449, 451, 453, 456, 458, 461, 466, 468, 473, 477, 485, 487, 490, 492, 502, 503, 509, 511, 512, 513, 515, 517, 518, 521, 522, 524, 525, 528, 536, 542, 545, 547, 548, 559, 564, 566, 567, 569, 571, 573, 577, 579, 584, 586, 589, 590, 591, 593, 595, 598, 602, 608, 613, 619, 622, 624, 628, 629, 632, 633, 634, 649, 656, 657, 658, 664, 668, 670, 674, 676, 683, 685, 689, 690, 698, 701, 708, 722, 724, 727, 734, 737, 739, 740, 742, 743, 746, 750, 757, 761, 762, 763, 765, 772, 773, 778, 783, 788, 789, 801, 803, 809, 812, 814, 816, 818, 819, 822, 823, 827, 835, 847, 849])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similars=lsh.findCosineSimilarsApproximatedMM()"
      ],
      "metadata": {
        "id": "-O_V7W3Q1EmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar=lsh.findCosineSimilarsApproximatedMMSingular(0)"
      ],
      "metadata": {
        "id": "bz6Rv1W79Zwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsh.jaccardAB()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAMVG9KN3I5Z",
        "outputId": "06b31710-94ee-4dd3-8440-5ab3a7089687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0028244411846011725"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Operations.jaccardSimilarity(lsh.A.intersection(lsh.B),lsh.A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgU9biiA6FBV",
        "outputId": "029aa47d-4bb9-41a2-fbdf-83454f2a1e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15774959571027322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"dima={len(lsh.A)}, dimB={len(lsh.B)} , difference={len(lsh.B.difference(lsh.A))} , intersection={len(lsh.B.intersection(lsh.A))} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDYQZL_r66SY",
        "outputId": "92fd7803-a844-432e-aa04-c28420834fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dima=58745, dimB=3231525 , difference=3222258 , intersection=9267 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISsEnDWn8p3R",
        "outputId": "a9fe0eec-42d2-4935-8ba7-b00989ab2a13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 33897)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lsh.testX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3kSv85iDQ6-",
        "outputId": "4543bebf-04ef-481f-f4a7-178e08fd6851"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6309898804344547"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fromsim=0.4\n",
        "top=1-np.arccos(fromsim)/np.pi\n",
        "top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCvzYEM4DmW0",
        "outputId": "2dbf8c4b-354f-401a-f9aa-59a50e3a8440"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30901699437494745"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "fromp=0.6\n",
        "tosim=np.cos((1-fromp)*np.pi)\n",
        "tosim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTjAvVx5_SXI"
      },
      "outputs": [],
      "source": [
        "a=lsh.findExactCosineSimilarsMM(0.4)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0FY40KOn8p3R"
      },
      "outputs": [],
      "source": [
        "a=lsh.findExactCosineSimilars(0.3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miEi6zh-QIWo"
      },
      "outputs": [],
      "source": [
        "lsh.exactSimilars=a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtE7UEzg_NwV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dm-hB72uxZI",
        "outputId": "76987e2c-a5a5-4c4c-d17e-8eb12976e7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(852, 100) (169684, 100)\n"
          ]
        }
      ],
      "source": [
        "lsh.generateMMM()\n",
        "print(lsh.mTest.shape,lsh.mTrain.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScPPiEHI8p3S"
      },
      "outputs": [],
      "source": [
        "lsh.generateM()\n",
        "lsh.mTest.shape\n",
        "lsh.mTrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsgJ6AFw8p3S"
      },
      "outputs": [],
      "source": [
        "mTest=lsh.mTest\n",
        "mTrain=lsh.mTrain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "HTqm0trc8p3T",
        "outputId": "389e5cf0-6019-4de4-a4d7-a8d5f5ac8405"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-3d94d1e90f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmTest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmTrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mTest' is not defined"
          ]
        }
      ],
      "source": [
        "lsh.mTest=mTest\n",
        "lsh.mTrain=mTrain\n",
        "len(lsh.mTest[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC2ugD8CL4DO"
      },
      "outputs": [],
      "source": [
        "lsh.lsh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQiMQQ0X8p3T"
      },
      "outputs": [],
      "source": [
        "lsh.r=33\n",
        "lsh.b=3\n",
        "lsh.lshMM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bXGSRR2h0VIr",
        "outputId": "7855f6c3-806f-4212-d6fa-842f8f817dd6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ciao'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lsh.findCosineSimilarsApproximatedMM()\n",
        "\"ciao\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOTnoNAo8p3T"
      },
      "outputs": [],
      "source": [
        "lsh.r=10\n",
        "lsh.b=100\n",
        "\n",
        "lsh.lsh()\n",
        "b=lsh.findCosineSimilarsApproximated()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "N1ZoDhSfxq-Q",
        "outputId": "90b2dcf3-5cff-42c3-f75a-e3c179b96b59"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-44f799847e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnHashes\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindCosineSimilarsApproximated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mjacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaccardAB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-9fd435f471ba>\u001b[0m in \u001b[0;36mlsh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowsTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m# print(i,j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashesUsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Lsh' object has no attribute 'mTrain'"
          ]
        }
      ],
      "source": [
        "#automatic search for b and r\n",
        "maxJaccard=0\n",
        "maxR=0\n",
        "maxB=0\n",
        "\n",
        "for i in range(1,int(lsh.nHashes**0.5)):\n",
        "\n",
        "  lsh.r=i\n",
        "  lsh.b=int(lsh.nHashes/i)\n",
        "  lsh.lsh()\n",
        "  b=lsh.findCosineSimilarsApproximated(0.123)\n",
        "  jacc=lsh.jaccardAB()\n",
        "  if jacc>maxJaccard:\n",
        "    maxJaccard=jacc\n",
        "    maxR=lsh.r\n",
        "    maxB=lsh.b\n",
        "\n",
        "\n",
        "\n",
        "  lsh.b=i\n",
        "  lsh.r=int(lsh.nHashes/i)\n",
        "  lsh.lsh()\n",
        "  b=lsh.findCosineSimilarsApproximated(0.123)\n",
        "  jacc=lsh.jaccardAB()\n",
        "  if jacc>maxJaccard:\n",
        "    maxJaccard=jacc\n",
        "    maxR=lsh.r\n",
        "    maxB=lsh.b\n",
        "\n",
        "print([maxJaccard,maxR,maxB])\n",
        "\n",
        "  \n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKNYVHjRfQa9",
        "outputId": "c855f1df-0938-4492-af27-7161cf8eefd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ],
      "source": [
        "lsh.optimizeRB(0.3,10)\n",
        "lsh.optimizeRB(0.2,10)\n",
        "lsh.optimizeRB(0.4,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "bLYyn6K8yWzj",
        "outputId": "66b289a1-3c3f-4db1-e61d-b5733ae6e647"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-1c11d491eb21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-7d9ea58b3711>\u001b[0m in \u001b[0;36moptimizeRB\u001b[0;34m(self, cosineSimilarity, nHashes)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnHashes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindExactCosineSimilars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnHashes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnHashes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mmaxTaken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-7d9ea58b3711>\u001b[0m in \u001b[0;36mfindExactCosineSimilars\u001b[0;34m(self, threshold)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexactSimilars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-132494f2be1a>\u001b[0m in \u001b[0;36mcosineSimilarity\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparseProduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2528\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lsh.optimizeRB(0.2,30)\n",
        "lsh.optimizeRB(0.3,30)\n",
        "lsh.optimizeRB(0.4,30)\n",
        "lsh.optimizeRB(0.2,40)\n",
        "lsh.optimizeRB(0.3,40)\n",
        "lsh.optimizeRB(0.4,40)\n",
        "lsh.optimizeRB(0.2,50)\n",
        "lsh.optimizeRB(0.3,50)\n",
        "lsh.optimizeRB(0.4,50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLcDylAG-L3w",
        "outputId": "bd157c3a-1478-4413-e81a-e3ebf942d796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.008841119213987123, 11, 9]\n",
            "0.025572569612991484\n",
            "[0.008108752683043167, 16, 6]\n",
            "0.010611735330836454\n",
            "[0.05005324813631523, 25, 4]\n",
            "0.050106609808102345\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.05005324813631523, 25, 4]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lsh.optimizeRBMM(0.2,1000)\n",
        "lsh.optimizeRBMM(0.3,100)\n",
        "lsh.optimizeRBMM(0.4,100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "auUE_kfOC-h9",
        "outputId": "e46e1844-ec06-4813-caec-5e36a05853bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.008708272859216255, 13, 15]\n",
            "0.017191977077363897\n",
            "[0.0020149683362118594, 10, 20]\n",
            "0.1794871794871795\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-36dc3d04fbc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizeRB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-7d9ea58b3711>\u001b[0m in \u001b[0;36moptimizeRB\u001b[0;34m(self, cosineSimilarity, nHashes)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnHashes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnHashes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mmaxTaken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0;31m#automatic search for b and r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-7d9ea58b3711>\u001b[0m in \u001b[0;36mgenerateM\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowsTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-132494f2be1a>\u001b[0m in \u001b[0;36mh\u001b[0;34m(x, u)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparseProduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-132494f2be1a>\u001b[0m in \u001b[0;36msparseProduct\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msparseProduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mmajor_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to this format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         idx_dtype = get_index_dtype((self.indptr, self.indices,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/csc.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     66\u001b[0m                     idx_dtype = get_index_dtype((indices, indptr),\n\u001b[1;32m     67\u001b[0m                                                 \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                                                 check_contents=True)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     self.indices = np.array(indices, copy=copy,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mget_index_dtype\u001b[0;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "lsh.optimizeRB(0.2,200)\n",
        "\n",
        "lsh.optimizeRB(0.3,200)\n",
        "\n",
        "lsh.optimizeRB(0.4,200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBHmNUdEDHYT"
      },
      "outputs": [],
      "source": [
        "lsh.optimizeRB(0.2,1000)\n",
        "lsh.optimizeRB(0.3,1000)\n",
        "lsh.optimizeRB(0.4,1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6eKgJDM6WS7U"
      },
      "outputs": [],
      "source": [
        "lsh.r=5\n",
        "lsh.b=2\n",
        "lsh.nHashes=lsh.b*lsh.r\n",
        "lsh.generateMMM()\n",
        "lsh.lshMM()\n",
        "lsh.findCosineSimilarsApproximatedMM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "O4-GcG3e8p3U",
        "outputId": "c4eef81b-22d1-40a3-954c-855b88de374f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0003733264675592173\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-32ba7a37dfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaccardAB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaccardSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlsh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# intersection=lsh.a.intersection(lsh.b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(len(intersection),len(lsh.a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Lsh' object has no attribute 'a'"
          ]
        }
      ],
      "source": [
        "print(lsh.jaccardAB())\n",
        "print(Operations.jaccardSimilarity(lsh.a.intersection(lsh.b),lsh.a))\n",
        "# intersection=lsh.a.intersection(lsh.b)\n",
        "# print(len(intersection),len(lsh.a))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "05c73f36370b37d7956a45e693a83b97388709ec0b54883dc202775cd3dcb887"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}