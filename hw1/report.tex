\documentclass{article}
\usepackage[utf8]{inputenc}

\title{First homework Big Data Computing}
\author{Andrea Morelli}
\date{October 2022}

\begin{document}

\maketitle

\section{}

\section{}
\subsection{a}
We have to compute $Var(S)$ with $S$ being 
$S=\frac{1}{n} \sum_{i=1}^n X_i$.\\
We start with $Var(\frac{1}{n} \sum_{i=1}^n X_i)$\\
$
\operatorname{Var}\left(\frac{X_1}{n}+\frac{X_2}{n}+\cdots \frac{X_n}{n}\right)
$\\
Then being the variance a squared function we can use the property of the variance $\operatorname{Var}(a X)=a^2 \operatorname{Var}(X)$\\
and derive $\frac{1}{n^2} \operatorname{Var}\left(X_1\right)+\frac{1}{n^2} \operatorname{Var}\left(X_2\right)+\cdots+\frac{1}{n^2} \operatorname{Var}\left(X_n\right)$\\
and being $Var(X_i)=\sigma^2$ we obtain\\
$\operatorname{Var}(S)=\frac{n \sigma^2}{n^2}=\frac{\sigma}{n}$


\subsection{b}
Given $Z=\frac{1}{n} \sum_{i=1}^n\left(X_i-S\right)^2$i have to compute $\mathbb{E}[Z]$ as a function of n and $\sigma^2$.
So i have to compute: $E\left(Z\right)=E\left[\frac{\sum_{i=1}^n\left(X_i-S\right)^2}{n}\right]$.\\I develop the square of a binomial term$$E\left[\frac{\sum_{i=1}^n\left(X_i^2 -2X_i S +S^2)}{n}\right]$$
Then distribute the sum
$$E\left[\frac{\sum_{i=1}^n X_i^2 \ -\sum_{i=1}^n 2X_i S +\sum_{i=1}^n S^2}{n}\right]$$
Then using $S=\frac{1}{n} \sum_{i=1}^n X_i$
$$E\left[\frac{(\sum_{i=1}^n X_i^2) \ -2 nS^2 + nS^2}{n}\right]$$
$$E\left[\frac{(\sum_{i=1}^n X_i^2) \ - nS^2 }{n}\right]$$
Then using the linearity of the expectation
\begin{equation}
\label{eqn:ez}
    E[Z]=\frac{(\sum_{i=1}^nE[ X_i^2]) - nE[S^2]}{n}
\end{equation}
Then using the property of the variance $\operatorname{Var}(X)=E\left[X^2\right]-(E[X])^2$
we have $$E[X^2]=\sigma^2+\mu^2$$
If applied on S and using the result of the "a" point we derive
$$E[S^2]=\frac{\sigma^2}{n}+\mu^2$$
Now applying those on \ref{eqn:ez} we obtain
$$E[Z]=\frac{(\sum_{i=1}^n\sigma^2+\mu^2) - n(\frac{\sigma^2}{n}+\mu^2)}{n}$$
Developing everything
$$\frac{n\sigma^2+n\mu^2 - \sigma^2-n\mu^2}{n}$$
Obtaining
$$E[Z]=\frac{(n-1)\sigma^2}{n}$$






















\section{}
In order to solve the third assigment i used the chernoff bound.
We want to estimate the fraction p of people that have been infected by a virus in a given population.
So we perform n tests sampled uniformly and independently at random from the population and each test will return the correct answer every time.
Given $0<\varepsilon<1   \ and  \ 0<\delta<1$ We want to find $\mathbb{P}(|\hat{p}-p|>\varepsilon p)<\delta$, whenever $p>\theta$,
where $\hat{p}$ is our estimator of p.\\
i start by defining \( X_{i}=\left\{\begin{array}{ll}1 & \text { if \ infected \ with \ proability \ p} \\ 0 & \text { if\ not \ infected \ with \ probability \ 1-p }\end{array}\right. \)
\\and $X=\sum ^{n}_{i=1}X_{i}$ .$\hat{p}$ that is our estimator will be \( \frac{1}{n} X \) (sample mean)and will have a mean equal to $p$.\\Using those we can use also use the chernoff bound:\\For $\varepsilon>0: \mathbf{P}[X \geq(1+\varepsilon) \mu]<e^{-\frac{\varepsilon^2}{3} \mu}$ where $\mu$ is the mean of $X$ and $X$ is $\sum ^{n}_{i=1}X_{i}$ with $X_{i}$ being an indipendent poisson trial.\\
Using $\hat{p}$ and p that is its mean we can write:\\
$$
P(|\hat{p}-p|>\varepsilon p)<2e^{-\frac{\varepsilon^2}{3} p}
$$
Use the 2 to take into account the module so both the tails of the distribution and not just one.\\
To use the form used by the chernoff bound we transform in the follwing way by just scaling everything with n:\\
$$
P(|X-np|>\varepsilon n p)<2e^{-\frac{\varepsilon^2}{3} np}
$$
Being this the maximum value it can assume we can write that :
$$2e^{-\frac{\varepsilon^2}{3} np}<\delta$$ and solving for n we can obtain the minimum number of n such that the initial condition holds.

$$
n>\ln \left(\frac{\delta}{2}\right) \cdot \frac{3}{\varepsilon^2 \rho}
$$



















\section{}
We can use the theorem 1.1 linked in the assignment 3.
\\Let $X=\sum_{i=0}^nX_i$ where $X_i \ \in [n]$ are indipendetly distributed in $[0,1]$.\\
Then for $0<\varepsilon<1$ , $\operatorname{Pr}[X>(1+\epsilon) \mathrm{E}[X]] \leq \exp \left(-\frac{\epsilon^2}{3} \mathrm{E}[X]\right)$.





\end{document}
